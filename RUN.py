import Dcleaner
import processdata
import tfBlitz
import model0
import cv2
import numpy as np

# 1. RUN THE RECORDDATA.PY TO RECORD THE GAME PLAY AT 20-30 FPS (BETTER THAN RECORDING AT 40-60 FPS)
#    ALL THE INSTRUCTIONS AND SETTINGS CAN BE FOUND ON RECORDDATA.PY
#    MORE THAN 500 FILES AT 2000 FRAMES PER FILE OF RECORDED GAMEPLAY AT 20-30 FPS IS ENOUGH TO TRAIN A GOOD DRIVING MODEL

# 2. IF THERE ARE DIRTY DATA FILES WITH DISTURBANCES WHICH YOU WANT TO REMOVE / CLEAN THOSE FILES THEN USE THE Dcleaner.py TO
#    GO THROUGH EACH FILE FRAME BY FRAMES AND TRIM OUT UNWANTED PARTS / FRAMES FROM THESE FILES AND SAVE THE CLEANED FILES TO A
#    SEPERATE FOLDER DIRECTORY
#    Dcleaner.py IS LIKE EDITING A VIDEO TO FIND UNWANTED PARTS BY REWINDING , PLAYING FORWARD , SKIPING AND TRIMING OUT UNWANTED PARTS.

DIRTY_DATA_FILEPATH=r'D:\self-driving-car-data\raw-data'
CLEANED_DATA_FILEPATH=r'D:\self-driving-car-data\clean-data' # recorded data files + some cleaned data files -->> should be about more than 500 files

Dcleaner.start2(DIRTY_DATA_FILEPATH,CLEANED_DATA_FILEPATH)

# 3. processdata.py WILL BE USED TO CHANGE LABELS FROM THE FORMAT [0,1,0,1] TO THE REQUIRED FORMAT [0,1,0,0,0,0,0,0,0]
#    WHERE [ W, A, S, D ,WA,WD,SA,SD,NONE ]
#    THEN THE LABELED DATA IS BALANCED WITH A CALCULATED BALANCING RATIO WHERE NUMBER OF W,WA,WD DATA ELEMENTS ARE 1.5 TIMES
#    GREATER THAN THE REST OF THE LABELS
#    HERE THE COLLECTED DATA WHICH IS IN .NPY FORMAT IS SAVED IN .TFRECORD FORMAT AT SAVE_PROCESSED_DATA_FILEPATH

SAVE_PROCESSED_DATA_FILEPATH=r'D:\self-driving-car-data\processed-data'

processdata.processdata(CLEANED_DATA_FILEPATH,SAVE_PROCESSED_DATA_FILEPATH)

# 4. USE getlabelinfo TO GET THE TOTAL NUMBER OF LABELS FROM THE BALANCED DATA FILES
#    THIS WAY WE CAN KEEP TRACK OF HOW OUR LABELS ARE BEING BALANCED AND TO CHECK IF THERE IS NO HIGHLY IMBALANCED LABELS

Dcleaner.getlabelinfo(SAVE_PROCESSED_DATA_FILEPATH)

# 5. TWEAKS TO SHUFFLE OUR DATASET WHICH WE CAN USE FOR TRAINING OR CHECKING OUR TFRECORD FILES
tweaks={
    'SHUFFLE_BUFFER_SIZE':1000,
    'BATCH_SIZE':40,
    'PREFETCH_NUM_OF_BATCHES':2
}

#    tfBlitz.py is tensorflow input pipeline made easy , normalize = True will return normalized data in float32 dtype used for training,
#    normalize = False will return the data as it is .
dataset = tfBlitz.dataset(SAVE_PROCESSED_DATA_FILEPATH,tweaks=tweaks,normalize=True)

# to check how well shuffled our data is and to make sure dataset generator is working properly
for x,y in dataset:
    cv2.imshow('check_data',np.array(x))  # VIEW EACH FRAMES NORMALIZED AND SHUFFLED
    cv2.waitKey(1)
    print(np.array(y))  # VIEW THE LABELS OF EACH FRAME

# 7. TRAINING THE MODEL USING tfBlitz train test dataset generator
SAVE_MODEL_FILEPATH = r'E:\AI DATA\models\self_driving_car'+tfBlitz.getdateandtime()
TRAINING_DATA_FILEPATH = SAVE_PROCESSED_DATA_FILEPATH
INPUTSHAPE = (300,400,1)
INPUTBATCH = 40

#    THIS FUNCTION WILL SPLIT THE BALANCED DATA FILES INTO TRAINING SET AND TESTING SET BY ADJUSTING VALIDATION_FILES_SPLIT = 0.2 (20 % TEST SET)
#    HERE VALIDATION DATA IS 4 % OF THE TOTAL DATASET

train_dataset , test_dataset = tfBlitz.train_test_datasets(
    TRAINING_DATA_FILEPATH,tweaks=tweaks,normalize=True,validation_files_split=0.04
)

#    TRAINING THE MODEL WITH INPUT SHAPE , BATCH SIZE , TWEAKS AND TRAIN_DATASET , TEST_DATASET GENERATED BY BALANCED DATASET TFRECORD FILES
model0.train_model(INPUTSHAPE,INPUTBATCH,SAVE_MODEL_FILEPATH,train_dataset,test_dataset)

# 8. RUN THE predictmodel.py FOR TESTING THE TRAINED MODEL , INSTRUCTIONS ARE FOUND ON predictmodel.py

###########################################################################################################################################################

#  THIS FUNCTION CAN BE USED TO CONVERT NUMPY FILES TO TFRECORD FILES.
NUMPY_FILES_DIRECTORY=r'file directory containing .npy files'
TFRECORD_FILES_DIRECTORY=r'file directory containing .tfrecord files'

tfBlitz.generatetfrecords(NUMPY_FILES_DIRECTORY,TFRECORD_FILES_DIRECTORY)
